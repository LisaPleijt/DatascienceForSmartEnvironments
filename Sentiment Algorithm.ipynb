{
 "cells": [
  {
   "source": [
    "# Sentiment Algorithm <p>\n",
    "This is the second jupyter notebook in the workflow. It includes the preparation & filtering of harvested Tweets, the translation of Tweets as well as the performance of the sentiment analysis  ."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> IMPORTING THE PACKAGES </b> - Several modules are used in this notebook. Next to common libraries, we use NLTK (Natural Language Toolkit), which represents a module to work with human language data.\n",
    "Furthermore, we use the library deep_translator, which facilitates access to a range of translation APIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk as nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "source": [
    "\n",
    "<b> OPENING CSV WITH RAW TWEETS </b> - The first step of the sentiment analyis is to load the dataset containing the the raw tweets derived from the Twitter API into a pandas dataframe (DF). This csv file is stored in a new variable called \"tweets\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://github.com/zyankarli/Data-Science-Course/blob/master/tweets.csv'\n",
    "tweets = pd.read_csv('https://raw.githubusercontent.com/zyankarli/Data-Science-Course/master/tweets_historic_full_text.csv?token=AP2IGIV7XDJVD2FDWPURZATAPFWVW')"
   ]
  },
  {
   "source": [
    "<b> DEFINITION OF FUNCTIONS </b> - within this cell, all the functions used in this notebook are defined. <p>\n",
    "DATA_CLEANING - This function converts the csv file into a pandas dataframe. Then, columns that are redundant are removed from the dataframe. Here, also privacy aspects are taken into account by deleting information related to the Twitter user. Furthermore, duplicate tweets are removed based on 'id-str' which is basically a unique identfication code for each tweet. <p>\n",
    "DATA_PER_CITY - This function filters the tweets per city. At this point, the csv contains tweets from the entire country. the 'loc' function is used to filter tweets based on 'user_location'. The 'city' parameter can be filled in manually and corresponds to the four cities we are investigating. After filtering, the subset of the csv is stored into a new csv and returned as 'tweets_city'. <p>\n",
    "FIND_CITY - The function here acts as a help function for the function described after this. From the package re, regular expressions are used to identify the words 'Amsterdam', 'Rotterdam', 'Utrecht', 'Den Haag' in every bio-location (the location manually set by the user). <p>\n",
    "ADD_CITY_COLUMN - This function uses the previous function where all words of the cities have been idenified. It creates a new column called 'city' where it puts -for every tweet- the name of each city where the tweet was posted. This extra column of city names helps later on to filter tweets from different cities for the sentiment algorithm. <p>\n",
    "ADD_DAY_COLUMN - This function basically converts the information in the dataframe column called 'created' into a date-time object. Currently this information is formatted as a string and in order to be able to filter on it for later analysis it needs to be a date-time object. It also saves a csv with the clean and filtered tweets to use for for visualization later. <p>\n",
    "TRANSLATOR - Translates a given text from any language into english. If no text is to be found, a Nan-value is returned."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining functions\n",
    "def data_cleaning(tweets):\n",
    "    tweets_df = pd.DataFrame(tweets)\n",
    "    tweets_df.drop(['coordinates','geo', 'user_created', 'user_name', 'user_followers', 'user_bg_color'], axis = 1, inplace = True)\n",
    "    tweets_df.drop_duplicates(subset = ['id_str'], keep = False, inplace = True)\n",
    "    return(tweets_df)\n",
    "\n",
    "## CAN THIS ONE BE DELETED ????????\n",
    "def data_per_city(tweets_df, city):\n",
    "    tweets_city = tweets_df.loc[tweets_df['user_location'] == city]\n",
    "    tweets_city.to_csv(r'~/Desktop/SmartEnvironments_Code/tweets_city1.csv', mode = 'a', index = False, header = True)\n",
    "    return tweets_city\n",
    "\n",
    "def find_city(string):\n",
    "    if len(re.findall(r'amsterdam', str(string))) != 0:\n",
    "        return 'Amsterdam'\n",
    "    elif len(re.findall(r'den haag', str(string))) != 0:\n",
    "        return 'Den Haag'\n",
    "    elif len(re.findall(r'rotterdam', str(string))) != 0:\n",
    "        return \"Rotterdam\"\n",
    "    elif len(re.findall(r'utrecht', str(string))) != 0:\n",
    "        return 'Utrecht'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def add_city_column(df):\n",
    "    clean_df = df\n",
    "    clean_df ['city'] = clean_df['user_location'].apply(find_city)\n",
    "    clean_df = clean_df.dropna()\n",
    "    return clean_df\n",
    "\n",
    "def add_day_column(df):\n",
    "    clean_df = df\n",
    "    clean_df['created'] = pd.to_datetime(clean_df['created'])\n",
    "    #create new column that only incorporates date\n",
    "    clean_df['date'] = clean_df['created'].dt.date\n",
    "    return clean_df\n",
    "\n",
    "def translator(text):\n",
    "    if len(text)>1:\n",
    "        return GoogleTranslator(source='auto', target='en').translate(text)\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "source": [
    "<b> CALLING ALL FUNCTIONS </b> - The following code block  simply calls all functions created above to execute them. The result is a dataframe cleaned, filtered and contains a correct city and date label."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          id                                   user_description  \\\n",
       "393      394                        Open, eerlijk , transparant   \n",
       "792      793  Observing this #plutocracy. Gezondheid lijkt v...   \n",
       "796      797                               ‚Ä¢ vrouw ‚Ä¢ liberaal ‚Ä¢   \n",
       "802      803  Kan niet tegen onrecht Probeer de waarheid te ...   \n",
       "803      804  https://t.co/PKtZwEPWDf\\nCouchsurfer\\nPolarste...   \n",
       "...      ...                                                ...   \n",
       "57385  57386       Wij brengen het nieuws uit uw regio in beeld   \n",
       "57397  57398  üá≥üá± Dutch | Vader | Feyenoord | Stemt rechts | ...   \n",
       "57398  57399  üá≥üá± Dutch | Vader | Feyenoord | Stemt rechts | ...   \n",
       "57401  57402  üá≥üá± Dutch | Vader | Feyenoord | Stemt rechts | ...   \n",
       "57404  57405  üá≥üá± Dutch | Vader | Feyenoord | Stemt rechts | ...   \n",
       "\n",
       "                       user_location  \\\n",
       "393             amsterdam, nederland   \n",
       "792        van galenbuurt, amsterdam   \n",
       "796          's-gravenhage & utrecht   \n",
       "802               utrecht, nederland   \n",
       "803    rotterdam blijdorp, nederland   \n",
       "...                              ...   \n",
       "57385            den haag, nederland   \n",
       "57397           rotterdam, nederland   \n",
       "57398           rotterdam, nederland   \n",
       "57401           rotterdam, nederland   \n",
       "57404           rotterdam, nederland   \n",
       "\n",
       "                                                    text               id_str  \\\n",
       "393    vanaf 15 mei quarantaineplicht bij aankomst ui...  1382689775170289666   \n",
       "792    hier heb ik een half jaar moeten wachten op ee...  1382679111039123456   \n",
       "796    voor een zelftest naar een particuliere testst...  1382678924954591236   \n",
       "802    er snel nog even een miljard doorheen jassen, ...  1382678534292901888   \n",
       "803    die afname in 2020 komt toch 'gewoon' door cor...  1382678530929070080   \n",
       "...                                                  ...                  ...   \n",
       "57385  √©√©n op de tien 75-plussers is eenzaam. de acti...  1380196413875875848   \n",
       "57397  ü§°üñïüèº #staatspropaganda ü§°üñïüèº er zijn nauwelijks b...  1380196054344273920   \n",
       "57398  ü§°üñïüèº #staatspropaganda ü§°üñïüèº er zijn nauwelijks b...  1380195939839848451   \n",
       "57401  ü§°üñïüèº #staatspropaganda ü§°üñïüèº er zijn nauwelijks b...  1380195795895529478   \n",
       "57404  ü§°üñïüèº #staatspropaganda ü§°üñïüèº er zijn nauwelijks b...  1380195740547485696   \n",
       "\n",
       "                  created  retweet_count       city        date  \n",
       "393   2021-04-15 13:38:26              0  Amsterdam  2021-04-15  \n",
       "792   2021-04-15 12:56:03              0  Amsterdam  2021-04-15  \n",
       "796   2021-04-15 12:55:19              0    Utrecht  2021-04-15  \n",
       "802   2021-04-15 12:53:46              0    Utrecht  2021-04-15  \n",
       "803   2021-04-15 12:53:45              0  Rotterdam  2021-04-15  \n",
       "...                   ...            ...        ...         ...  \n",
       "57385 2021-04-08 16:30:42              1   Den Haag  2021-04-08  \n",
       "57397 2021-04-08 16:29:16              0  Rotterdam  2021-04-08  \n",
       "57398 2021-04-08 16:28:49              0  Rotterdam  2021-04-08  \n",
       "57401 2021-04-08 16:28:15              0  Rotterdam  2021-04-08  \n",
       "57404 2021-04-08 16:28:02              0  Rotterdam  2021-04-08  \n",
       "\n",
       "[4862 rows x 9 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>user_description</th>\n      <th>user_location</th>\n      <th>text</th>\n      <th>id_str</th>\n      <th>created</th>\n      <th>retweet_count</th>\n      <th>city</th>\n      <th>date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>393</th>\n      <td>394</td>\n      <td>Open, eerlijk , transparant</td>\n      <td>amsterdam, nederland</td>\n      <td>vanaf 15 mei quarantaineplicht bij aankomst ui...</td>\n      <td>1382689775170289666</td>\n      <td>2021-04-15 13:38:26</td>\n      <td>0</td>\n      <td>Amsterdam</td>\n      <td>2021-04-15</td>\n    </tr>\n    <tr>\n      <th>792</th>\n      <td>793</td>\n      <td>Observing this #plutocracy. Gezondheid lijkt v...</td>\n      <td>van galenbuurt, amsterdam</td>\n      <td>hier heb ik een half jaar moeten wachten op ee...</td>\n      <td>1382679111039123456</td>\n      <td>2021-04-15 12:56:03</td>\n      <td>0</td>\n      <td>Amsterdam</td>\n      <td>2021-04-15</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>797</td>\n      <td>‚Ä¢ vrouw ‚Ä¢ liberaal ‚Ä¢</td>\n      <td>'s-gravenhage &amp; utrecht</td>\n      <td>voor een zelftest naar een particuliere testst...</td>\n      <td>1382678924954591236</td>\n      <td>2021-04-15 12:55:19</td>\n      <td>0</td>\n      <td>Utrecht</td>\n      <td>2021-04-15</td>\n    </tr>\n    <tr>\n      <th>802</th>\n      <td>803</td>\n      <td>Kan niet tegen onrecht Probeer de waarheid te ...</td>\n      <td>utrecht, nederland</td>\n      <td>er snel nog even een miljard doorheen jassen, ...</td>\n      <td>1382678534292901888</td>\n      <td>2021-04-15 12:53:46</td>\n      <td>0</td>\n      <td>Utrecht</td>\n      <td>2021-04-15</td>\n    </tr>\n    <tr>\n      <th>803</th>\n      <td>804</td>\n      <td>https://t.co/PKtZwEPWDf\\nCouchsurfer\\nPolarste...</td>\n      <td>rotterdam blijdorp, nederland</td>\n      <td>die afname in 2020 komt toch 'gewoon' door cor...</td>\n      <td>1382678530929070080</td>\n      <td>2021-04-15 12:53:45</td>\n      <td>0</td>\n      <td>Rotterdam</td>\n      <td>2021-04-15</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>57385</th>\n      <td>57386</td>\n      <td>Wij brengen het nieuws uit uw regio in beeld</td>\n      <td>den haag, nederland</td>\n      <td>√©√©n op de tien 75-plussers is eenzaam. de acti...</td>\n      <td>1380196413875875848</td>\n      <td>2021-04-08 16:30:42</td>\n      <td>1</td>\n      <td>Den Haag</td>\n      <td>2021-04-08</td>\n    </tr>\n    <tr>\n      <th>57397</th>\n      <td>57398</td>\n      <td>üá≥üá± Dutch | Vader | Feyenoord | Stemt rechts | ...</td>\n      <td>rotterdam, nederland</td>\n      <td>ü§°üñïüèº #staatspropaganda ü§°üñïüèº er zijn nauwelijks b...</td>\n      <td>1380196054344273920</td>\n      <td>2021-04-08 16:29:16</td>\n      <td>0</td>\n      <td>Rotterdam</td>\n      <td>2021-04-08</td>\n    </tr>\n    <tr>\n      <th>57398</th>\n      <td>57399</td>\n      <td>üá≥üá± Dutch | Vader | Feyenoord | Stemt rechts | ...</td>\n      <td>rotterdam, nederland</td>\n      <td>ü§°üñïüèº #staatspropaganda ü§°üñïüèº er zijn nauwelijks b...</td>\n      <td>1380195939839848451</td>\n      <td>2021-04-08 16:28:49</td>\n      <td>0</td>\n      <td>Rotterdam</td>\n      <td>2021-04-08</td>\n    </tr>\n    <tr>\n      <th>57401</th>\n      <td>57402</td>\n      <td>üá≥üá± Dutch | Vader | Feyenoord | Stemt rechts | ...</td>\n      <td>rotterdam, nederland</td>\n      <td>ü§°üñïüèº #staatspropaganda ü§°üñïüèº er zijn nauwelijks b...</td>\n      <td>1380195795895529478</td>\n      <td>2021-04-08 16:28:15</td>\n      <td>0</td>\n      <td>Rotterdam</td>\n      <td>2021-04-08</td>\n    </tr>\n    <tr>\n      <th>57404</th>\n      <td>57405</td>\n      <td>üá≥üá± Dutch | Vader | Feyenoord | Stemt rechts | ...</td>\n      <td>rotterdam, nederland</td>\n      <td>ü§°üñïüèº #staatspropaganda ü§°üñïüèº er zijn nauwelijks b...</td>\n      <td>1380195740547485696</td>\n      <td>2021-04-08 16:28:02</td>\n      <td>0</td>\n      <td>Rotterdam</td>\n      <td>2021-04-08</td>\n    </tr>\n  </tbody>\n</table>\n<p>4862 rows √ó 9 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df = data_cleaning(tweets)\n",
    "df = add_city_column(df)\n",
    "df = add_day_column(df)\n",
    "df"
   ]
  },
  {
   "source": [
    "<b> TRANSLATION </b> - Translate all tweets in the dataframe. Takes very long (about two hours) for 4800 tweets. In order to avoid you running this cell unintetionally, the code is kept as a comment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#might take some time!\n",
    "#df['text_eng']=df['text'].apply(translator)"
   ]
  },
  {
   "source": [
    "<b>APPLYING SENTIMENT ANALYSIS </b> - Here the 'SentimentIntensityAnalyzer' tool of the 'NLTK' package is used to execute the sentiment analysis and assigned to a variable 'vader'. Within this cell, five new columns are defined and added to the dataframe. The first three columns save the respective values of the polarity_scores function of the SentimentIntensityAnalyzer for each tweet-text. The polarity_scores function returns a score for each of the three categories: negative ('neg'), neutral ('neu') and positive ('pos'). The compound score, which is added afterwards, aggregates these polarity scores on a number between -1 and +1, where -1 indicates very negative and +1 very positive sentiment . Finally, within the 'sentiment' column,the compound score is translated into one of the three sentiment categories. Commonly, texts that exhibit a compound score of equal to or higher than 0.05 are understood to express a positive sentiment. Therefore, such tweet-texts get labelled as positive. On the other hand, Tweets that exhibit a compound score equal or lower than -0.05 get labelled as negative. For every polarity score in between, the tweet is considered neutral. For each column definition, the apply-function, which allows to execute a specified funtion on every cell, to is used. In our case, we use lambda-statements as inputs for apply-functions to define single-lined functions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vader = SentimentIntensityAnalyzer()\n",
    "#rather seperate scores in columns\n",
    "df['neg'] = df['text_eng'].apply(lambda x:vader.polarity_scores(x)['neg'])\n",
    "df['neu'] = df['text_eng'].apply(lambda x:vader.polarity_scores(x)['neu'])\n",
    "df['pos'] = df['text_eng'].apply(lambda x:vader.polarity_scores(x)['pos'])\n",
    "df['compound'] = df['text_eng'].apply(lambda x:vader.polarity_scores(x)['compound'])\n",
    "\n",
    "#set highest sentiment column as sentiment of tweet\n",
    "#positive sentiment : (compound score >= 0.05)\n",
    "#neutral sentiment : (compound score > -0.05) and (compound score < 0.05)\n",
    "#negative sentiment : (compound score <= -0.05)\n",
    "#source: https://www.geeksforgeeks.org/python-sentiment-analysis-using-vader/\n",
    "df['sentiment'] = df['compound'].apply(lambda i: 'positive' if i >= 0.05 else ('negative' if i <= -0.05 else 'neutral'))"
   ]
  },
  {
   "source": [
    "<b> CHECK THE OUTPUT  </b> - Here simply the output of the sentiment analysis is checked by showing the first rows of the dataframe that now includes a new column indicating the sentiment score."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id                                   user_description  \\\n",
       "393  394                        Open, eerlijk , transparant   \n",
       "792  793  Observing this #plutocracy. Gezondheid lijkt v...   \n",
       "796  797                               ‚Ä¢ vrouw ‚Ä¢ liberaal ‚Ä¢   \n",
       "802  803  Kan niet tegen onrecht Probeer de waarheid te ...   \n",
       "803  804  https://t.co/PKtZwEPWDf\\nCouchsurfer\\nPolarste...   \n",
       "\n",
       "                     user_location  \\\n",
       "393           amsterdam, nederland   \n",
       "792      van galenbuurt, amsterdam   \n",
       "796        's-gravenhage & utrecht   \n",
       "802             utrecht, nederland   \n",
       "803  rotterdam blijdorp, nederland   \n",
       "\n",
       "                                                  text               id_str  \\\n",
       "393  vanaf 15 mei quarantaineplicht bij aankomst ui...  1382689775170289666   \n",
       "792  hier heb ik een half jaar moeten wachten op ee...  1382679111039123456   \n",
       "796  voor een zelftest naar een particuliere testst...  1382678924954591236   \n",
       "802  er snel nog even een miljard doorheen jassen, ...  1382678534292901888   \n",
       "803  die afname in 2020 komt toch 'gewoon' door cor...  1382678530929070080   \n",
       "\n",
       "                created  retweet_count       city        date  \\\n",
       "393 2021-04-15 13:38:26              0  Amsterdam  2021-04-15   \n",
       "792 2021-04-15 12:56:03              0  Amsterdam  2021-04-15   \n",
       "796 2021-04-15 12:55:19              0    Utrecht  2021-04-15   \n",
       "802 2021-04-15 12:53:46              0    Utrecht  2021-04-15   \n",
       "803 2021-04-15 12:53:45              0  Rotterdam  2021-04-15   \n",
       "\n",
       "                                              text_eng    neg    neu    pos  \\\n",
       "393  from 15 May, quarantine obligation upon arriva...  0.115  0.816  0.069   \n",
       "792  here I had to wait six months for a new indica...  0.141  0.772  0.087   \n",
       "796  for a self-test to a private test lane? #coron...  0.000  1.000  0.000   \n",
       "802  a billion more quickly, for which poor Netherl...  0.331  0.669  0.000   \n",
       "803  that decrease in 2020 is 'just' due to corona,...  0.000  1.000  0.000   \n",
       "\n",
       "     compound sentiment  \n",
       "393   -0.3612  negative  \n",
       "792   -0.1779  negative  \n",
       "796    0.0000   neutral  \n",
       "802   -0.8849  negative  \n",
       "803    0.0000   neutral  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>user_description</th>\n      <th>user_location</th>\n      <th>text</th>\n      <th>id_str</th>\n      <th>created</th>\n      <th>retweet_count</th>\n      <th>city</th>\n      <th>date</th>\n      <th>text_eng</th>\n      <th>neg</th>\n      <th>neu</th>\n      <th>pos</th>\n      <th>compound</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>393</th>\n      <td>394</td>\n      <td>Open, eerlijk , transparant</td>\n      <td>amsterdam, nederland</td>\n      <td>vanaf 15 mei quarantaineplicht bij aankomst ui...</td>\n      <td>1382689775170289666</td>\n      <td>2021-04-15 13:38:26</td>\n      <td>0</td>\n      <td>Amsterdam</td>\n      <td>2021-04-15</td>\n      <td>from 15 May, quarantine obligation upon arriva...</td>\n      <td>0.115</td>\n      <td>0.816</td>\n      <td>0.069</td>\n      <td>-0.3612</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>792</th>\n      <td>793</td>\n      <td>Observing this #plutocracy. Gezondheid lijkt v...</td>\n      <td>van galenbuurt, amsterdam</td>\n      <td>hier heb ik een half jaar moeten wachten op ee...</td>\n      <td>1382679111039123456</td>\n      <td>2021-04-15 12:56:03</td>\n      <td>0</td>\n      <td>Amsterdam</td>\n      <td>2021-04-15</td>\n      <td>here I had to wait six months for a new indica...</td>\n      <td>0.141</td>\n      <td>0.772</td>\n      <td>0.087</td>\n      <td>-0.1779</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>797</td>\n      <td>‚Ä¢ vrouw ‚Ä¢ liberaal ‚Ä¢</td>\n      <td>'s-gravenhage &amp; utrecht</td>\n      <td>voor een zelftest naar een particuliere testst...</td>\n      <td>1382678924954591236</td>\n      <td>2021-04-15 12:55:19</td>\n      <td>0</td>\n      <td>Utrecht</td>\n      <td>2021-04-15</td>\n      <td>for a self-test to a private test lane? #coron...</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>802</th>\n      <td>803</td>\n      <td>Kan niet tegen onrecht Probeer de waarheid te ...</td>\n      <td>utrecht, nederland</td>\n      <td>er snel nog even een miljard doorheen jassen, ...</td>\n      <td>1382678534292901888</td>\n      <td>2021-04-15 12:53:46</td>\n      <td>0</td>\n      <td>Utrecht</td>\n      <td>2021-04-15</td>\n      <td>a billion more quickly, for which poor Netherl...</td>\n      <td>0.331</td>\n      <td>0.669</td>\n      <td>0.000</td>\n      <td>-0.8849</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>803</th>\n      <td>804</td>\n      <td>https://t.co/PKtZwEPWDf\\nCouchsurfer\\nPolarste...</td>\n      <td>rotterdam blijdorp, nederland</td>\n      <td>die afname in 2020 komt toch 'gewoon' door cor...</td>\n      <td>1382678530929070080</td>\n      <td>2021-04-15 12:53:45</td>\n      <td>0</td>\n      <td>Rotterdam</td>\n      <td>2021-04-15</td>\n      <td>that decrease in 2020 is 'just' due to corona,...</td>\n      <td>0.000</td>\n      <td>1.000</td>\n      <td>0.000</td>\n      <td>0.0000</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "source": [
    "<b> EXPORT </b> - Save filtered and translated DF into a csv-file. In order to avoid you running this cell unintetionally, the code is kept as a comment."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('Filtered_Tweets.csv', mode = 'a', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion / Conclusion\n",
    "Two crucial decisions are made in this notebook. <p>\n",
    "The first decision concerns the type of sentiment analysis conducted. Several alternatives to conduct sentiment analyses in Python are available, amongst others the Google Natural Language API a self-trained Bayesian machine learning algorithm. However, we decided to use the VADER Sentiment Analyzer due to three reasons: scientific recognition, code transparency and simplicity.\n",
    "Firstly, Elbagir & Yang (2019) conclude in their paper that the VADER Sentiment Analyzer is a ‚Äòan effective choice for sentiment analysis classification using Twitter data.‚Äô (Elbagir & Yang. 2019. p.5). \n",
    "Furthermore, the algorithm is able to take into account hashtags, punctuation marks as well as capital letters. This reinsured us, that the algorithm is capable to deliver high-qualitative results.\n",
    "Secondly, the VADER Sentiment Analyzer is less a black box than alternatives would be. Under the following link, the source code is freely accessible: https://www.nltk.org/_modules/nltk/sentiment/vader.html. Finally, the VADER Sentiment Analyzer proved to be easy to implement and promised to yield results that are relatively easy to interpret. Moreover, the algorithm can handle larger dataset without problems.\n",
    "\n",
    "The second decision concerns whether to translate the Dutch tweets or not. It is clear, that the sentiment analysis is in danger of getting blurred when translating Dutch tweets into English language, which is required for the use of the VADER Sentiment Analyzer. The alternative would have been, to translate the lexicons underlying the VADER Sentiment Analyzer, i.e. to translate the algorithm into Dutch. However, Mohammad et al (2016) show in their study that both approaches deliver similar results. Therefore, we decided to translate all relevant Tweets using Google Translate via the Pyhton deep_translator package.\n",
    "\n",
    "References: <p>\n",
    "Elbagir, S., Yang, J. 2019. Proceedings of the International MultiConference of Engineers and Computer Scientists 2019, IMECS 2019, March 13-15, Hong Kong. <p>\n",
    "Mohammad, S.,  Salameh, M., & Kiritchenko, S. (2016). How Translation Alters Sentiment. J. Artif. Intell. Res. (JAIR). 55. 95-130. 10.1613/jair.4787."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0707a5b1a4a5ea3ec59dc95a60805d229947cb45f0531b316c1d7dc4904b44e4e",
   "display_name": "Python 3.8.8 64-bit ('NLTK_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}